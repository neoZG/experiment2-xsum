model:
  bitnet:
    hf_name: microsoft/bitnet-b1.58-2B-4T-bf16
    type: causal
  bart:
    hf_name: facebook/bart-large
    type: seq2seq
  mbart:
    hf_name: facebook/mbart-large-50
    type: seq2seq
  gemma:
    hf_name: google/gemma-2b
    type: causal
  gpt_neox:
    hf_name: EleutherAI/gpt-neo-2.7B
    type: causal

dataset:
  xsum:
    languages: ["en"]
  xlsum:
    languages: ["en", "es", "hi", "am", "si", "ha"]

training:
  batch_size: 2
  lr: 1e-4
  epochs: 2
  max_train: 1000
  max_val: 100
  gradient_checkpointing: true
  fp16: true

generation:
  beam: 4
  max_gen_len: 60
